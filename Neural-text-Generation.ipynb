{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N-Grams.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EawpF9qSnnoi",
        "outputId": "cb67afc4-664f-4d7c-ecd2-2010fdaa70f5"
      },
      "source": [
        "!pip install -q -U trax\n",
        "import trax"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 629 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 40.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 152 kB 60.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 249 kB 71.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 56.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 366 kB 63.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 50.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 35.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 31.8 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUA3eM06oHLw"
      },
      "source": [
        "import os\n",
        "import trax\n",
        "import trax.fastmath.numpy as np\n",
        "import pickle\n",
        "import numpy\n",
        "import random as rnd\n",
        "from trax import fastmath\n",
        "from trax import layers as tl\n",
        "import tensorflow as tf\n",
        "\n",
        "rnd.seed(32)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAf2w1nboxmy",
        "outputId": "cf143cd5-f326-4e10-ec9c-be64a5a54805"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "   raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgPGx2xfcXK7",
        "outputId": "0620d17c-8c9d-411a-bf44-4bc6948db55c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# change to working tensorflow directory on the drive\n",
        "#%cd '/content/gdrive/My Drive/models/'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz0C1b-ycuuK",
        "outputId": "058af191-9824-4982-a719-8d2b674ff13f"
      },
      "source": [
        "%cd '/content/gdrive/My Drive/Hafez'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Hafez\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMXGgT5UczOK",
        "outputId": "15137e8e-29e2-4c67-bd48-b0ae250cbedf"
      },
      "source": [
        "\n",
        "Vocab={'':0,'__EOS__':1,'__UNK__':2}\n",
        "\n",
        "lines=[]\n",
        "\n",
        "with open('./all_ghazals.txt',encoding=\"utf8\") as f:\n",
        "\n",
        "    for ln in f:\n",
        "        #print(ln)\n",
        "\n",
        "        if ln.strip():\n",
        "            #print(ln)\n",
        "            if '\\u200c' in ln:\n",
        "                continue\n",
        "            ln = ln.strip('\\n')\n",
        "            if len(ln.replace(\" \",\"\"))<10:\n",
        "                #print('not word')\n",
        "                #print(ln)\n",
        "                continue\n",
        "\n",
        "            else:\n",
        "                lines.append(ln)\n",
        "                for c in ln:\n",
        "\n",
        "                    if c not in Vocab:\n",
        "\n",
        "                        Vocab[c]=len(Vocab)\n",
        "\n",
        "\n",
        "print(Vocab)\n",
        "print(len(Vocab))\n",
        "print(lines[:10])\n",
        "print(len(lines))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'': 0, '__EOS__': 1, '__UNK__': 2, 'ا': 3, 'ل': 4, ' ': 5, 'ي': 6, 'ه': 7, 'س': 8, 'ق': 9, 'ی': 10, 'د': 11, 'ر': 12, 'ک': 13, 'و': 14, 'ن': 15, 'م': 16, 'ز': 17, 'ج': 18, 'چ': 19, 'ع': 20, 'ش': 21, 'ب': 22, 'گ': 23, 'ت': 24, 'پ': 25, 'غ': 26, 'خ': 27, 'آ': 28, 'ص': 29, 'ح': 30, 'ف': 31, 'ظ': 32, 'ط': 33, 'ث': 34, 'ض': 35, 'ذ': 36, 'ژ': 37, 'Y': 38}\n",
            "39\n",
            "['الا يا ايها الساقی ادر کاسا و ناولها', 'مرا در منزل جانان چه امن عيش چون هر دم', 'به می سجاده رنگين کن گرت پير مغان گويد', 'شب تاريک و بيم موج و گردابی چنين هايل', 'همه کارم ز خود کامی به بدنامی کشيد آخر', 'متی ما تلق من تهوی دع الدنيا و اهملها', 'صلاح کار کجا و من خراب کجا', 'ببين تفاوت ره کز کجاست تا به کجا', 'دلم ز صومعه بگرفت و خرقه سالوس', 'کجاست دير مغان و شراب ناب کجا']\n",
            "7029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0KzZCkzdFCN",
        "outputId": "3488188d-3ba6-41de-bf9c-901e5942bcbb"
      },
      "source": [
        "eval_lines=lines[-1000:]\n",
        "lines=lines[:-1000]\n",
        "print(f\"Number of lines for training: {len(lines)}\")\n",
        "print(f\"Number of lines for validation: {len(eval_lines)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines for training: 6029\n",
            "Number of lines for validation: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBeMZsvwg3Cy"
      },
      "source": [
        "def line_to_tensor(line,vocab_dict, EOS_int=1):\n",
        "    \"\"\"Turns a line of text into a tensor\n",
        "\n",
        "    Args:\n",
        "        line (str): A single line of text.\n",
        "        EOS_int (int, optional): End-of-sentence integer. Defaults to 1.\n",
        "\n",
        "    Returns:\n",
        "        list: a list of integers (unicode values) for the characters in the `line`.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize the tensor as an empty list\n",
        "    tensor = []\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    # for each character:\n",
        "    for c in line:\n",
        "\n",
        "        if c in vocab_dict:\n",
        "\n",
        "          c_int = vocab_dict[c]\n",
        "\n",
        "        else:\n",
        "\n",
        "          c_int = vocab_dict['__UNK__']\n",
        "\n",
        "        \n",
        "     \n",
        "        \n",
        "        \n",
        "        # append the unicode integer to the tensor list\n",
        "        tensor.append(c_int)\n",
        "    \n",
        "    # include the end-of-sentence integer\n",
        "    tensor.append(EOS_int)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return tensor"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPKc0lfFhetb",
        "outputId": "6165a1db-816d-4a17-cf1a-d463e3975cea"
      },
      "source": [
        "print('the sentence is: \\n',lines[0])\n",
        "print('tensor is :',line_to_tensor(lines[0],Vocab,EOS_int=1))\n",
        "\n",
        "print('tensor is :',line_to_tensor('lines[0]',Vocab,EOS_int=1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the sentence is: \n",
            " الا يا ايها الساقی ادر کاسا و ناولها\n",
            "tensor is : [3, 4, 3, 5, 6, 3, 5, 3, 6, 7, 3, 5, 3, 4, 8, 3, 9, 10, 5, 3, 11, 12, 5, 13, 3, 8, 3, 5, 14, 5, 15, 3, 14, 4, 7, 3, 1]\n",
            "tensor is : [2, 2, 2, 2, 2, 2, 2, 2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvu2s7IRhzi5"
      },
      "source": [
        "def data_generator(batch_size, max_length, data_lines, vocab_dict,line_to_tensor=line_to_tensor, shuffle=True):\n",
        "    \"\"\"Generator function that yields batches of data\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): number of examples (in this case, sentences) per batch.\n",
        "        max_length (int): maximum length of the output tensor.\n",
        "        NOTE: max_length includes the end-of-sentence character that will be added\n",
        "                to the tensor.  \n",
        "                Keep in mind that the length of the tensor is always 1 + the length\n",
        "                of the original line of characters.\n",
        "        data_lines (list): list of the sentences to group into batches.\n",
        "        line_to_tensor (function, optional): function that converts line to tensor. Defaults to line_to_tensor.\n",
        "        shuffle (bool, optional): True if the generator should generate random batches of data. Defaults to True.\n",
        "\n",
        "    Yields:\n",
        "        tuple: two copies of the batch (jax.interpreters.xla.DeviceArray) and mask (jax.interpreters.xla.DeviceArray).\n",
        "        NOTE: jax.interpreters.xla.DeviceArray is trax's version of numpy.ndarray\n",
        "    \"\"\"\n",
        "    # initialize the index that points to the current position in the lines index array\n",
        "    index = 0\n",
        "    \n",
        "    # initialize the list that will contain the current batch\n",
        "    cur_batch = []\n",
        "    \n",
        "    # count the number of lines in data_lines\n",
        "    num_lines = len(data_lines)\n",
        "    \n",
        "    # create an array with the indexes of data_lines that can be shuffled\n",
        "    lines_index = [*range(num_lines)]\n",
        "    \n",
        "    # shuffle line indexes if shuffle is set to True\n",
        "    if shuffle:\n",
        "        rnd.shuffle(lines_index)\n",
        "    \n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    while True:\n",
        "        \n",
        "        # if the index is greater or equal than to the number of lines in data_lines\n",
        "        if index>=num_lines:\n",
        "            # then reset the index to 0\n",
        "            index = 0\n",
        "            # shuffle line indexes if shuffle is set to True\n",
        "            if shuffle:\n",
        "                rnd.shuffle(lines_index)\n",
        "            \n",
        "        # get a line at the `lines_index[index]` position in data_lines\n",
        "        line = data_lines[lines_index[index]]\n",
        "        \n",
        "        # if the length of the line is less than max_length\n",
        "        if len(line)<max_length:\n",
        "            # append the line to the current batch\n",
        "            cur_batch.append(line)\n",
        "            \n",
        "        # increment the index by one\n",
        "        index += 1\n",
        "        \n",
        "        # if the current batch is now equal to the desired batch size\n",
        "        if len(cur_batch)==batch_size:\n",
        "            \n",
        "            batch = []\n",
        "            mask = []\n",
        "            \n",
        "            # go through each line (li) in cur_batch\n",
        "            for li in cur_batch:\n",
        "                # convert the line (li) to a tensor of integers\n",
        "                tensor = line_to_tensor(li,vocab_dict)\n",
        "                \n",
        "                # Create a list of zeros to represent the padding\n",
        "                # so that the tensor plus padding will have length `max_length`\n",
        "                pad = [0] * (max_length-len(tensor))\n",
        "                \n",
        "                # combine the tensor plus pad\n",
        "                tensor_pad = tensor+pad\n",
        "                \n",
        "                # append the padded tensor to the batch\n",
        "                batch.append(tensor_pad)\n",
        "\n",
        "                # A mask for  tensor_pad is 1 wherever tensor_pad is not\n",
        "                # 0 and 0 wherever tensor_pad is 0, i.e. if tensor_pad is\n",
        "                # [1, 2, 3, 0, 0, 0] then example_mask should be\n",
        "                # [1, 1, 1, 0, 0, 0]\n",
        "                # Hint: Use a list comprehension for this\n",
        "                example_mask = [1]*len(tensor)+[0]*len(pad)\n",
        "              \n",
        "                mask.append(example_mask)\n",
        "               \n",
        "            # convert the batch (data type list) to a trax's numpy array\n",
        "            batch_np_arr = np.array(batch)\n",
        "            mask_np_arr = np.array(mask)\n",
        "            \n",
        "            ### END CODE HERE ##\n",
        "            \n",
        "            # Yield two copies of the batch and mask.\n",
        "            yield batch_np_arr, batch_np_arr, mask_np_arr\n",
        "            \n",
        "            # reset the current batch to an empty list\n",
        "            cur_batch = []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDNMpKYhjo7p",
        "outputId": "1b261971-f8fa-456e-a215-fae9345a098b"
      },
      "source": [
        "tmp_data_gen = data_generator(batch_size=2, \n",
        "                              max_length=64, \n",
        "                              data_lines=lines[:10],vocab_dict=Vocab,\n",
        "                              shuffle=False)\n",
        "\n",
        "# get one batch\n",
        "import itertools\n",
        "infinite_data_generator = itertools.cycle(tmp_data_gen)\n",
        "tmp_batch = next(tmp_data_gen)\n",
        "\n",
        "# view the batch\n",
        "tmp_batch"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray([[ 3,  4,  3,  5,  6,  3,  5,  3,  6,  7,  3,  5,  3,  4,  8,\n",
              "                3,  9, 10,  5,  3, 11, 12,  5, 13,  3,  8,  3,  5, 14,  5,\n",
              "               15,  3, 14,  4,  7,  3,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0],\n",
              "              [16, 12,  3,  5, 11, 12,  5, 16, 15, 17,  4,  5, 18,  3, 15,\n",
              "                3, 15,  5, 19,  7,  5,  3, 16, 15,  5, 20,  6, 21,  5, 19,\n",
              "               14, 15,  5,  7, 12,  5, 11, 16,  1,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0]], dtype=int32),\n",
              " DeviceArray([[ 3,  4,  3,  5,  6,  3,  5,  3,  6,  7,  3,  5,  3,  4,  8,\n",
              "                3,  9, 10,  5,  3, 11, 12,  5, 13,  3,  8,  3,  5, 14,  5,\n",
              "               15,  3, 14,  4,  7,  3,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0],\n",
              "              [16, 12,  3,  5, 11, 12,  5, 16, 15, 17,  4,  5, 18,  3, 15,\n",
              "                3, 15,  5, 19,  7,  5,  3, 16, 15,  5, 20,  6, 21,  5, 19,\n",
              "               14, 15,  5,  7, 12,  5, 11, 16,  1,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "                0,  0,  0,  0]], dtype=int32),\n",
              " DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "               0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "               0, 0, 0, 0],\n",
              "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "               0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "               0, 0, 0, 0]], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0V6H0iGpE2y"
      },
      "source": [
        "def GRULM(vocab_size=256, d_model=512, n_layers=2, mode='train'):\n",
        "    \"\"\"Returns a GRU language model.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int, optional): Size of the vocabulary. Defaults to 256.\n",
        "        d_model (int, optional): Depth of embedding (n_units in the GRU cell). Defaults to 512.\n",
        "        n_layers (int, optional): Number of GRU layers. Defaults to 2.\n",
        "        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to \"train\".\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Serial: A GRU language model as a layer that maps from a tensor of tokens to activations over a vocab set.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    model = tl.Serial(\n",
        "      tl.ShiftRight(n_positions=1,mode='train'), # Stack the ShiftRight layer\n",
        "      tl.Embedding(vocab_size,d_model), # Stack the embedding layer\n",
        "      [tl.GRU(n_units=d_model) for _ in range(n_layers)], # Stack GRU layers of d_model units keeping n_layer parameter in mind (use list comprehension syntax)\n",
        "      tl.Dense(n_units=d_model), # Dense layer\n",
        "      tl.LogSoftmax() # Log Softmax\n",
        "    )\n",
        "    ### END CODE HERE ###\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiaCG9_bnRka",
        "outputId": "261509ce-4348-4f30-ae53-6044ca9736d2"
      },
      "source": [
        "# testing your model\n",
        "model = GRULM(vocab_size=len(Vocab), d_model=512, n_layers=2, mode='train')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  Serial[\n",
            "    ShiftRight(1)\n",
            "  ]\n",
            "  Embedding_39_512\n",
            "  GRU_512\n",
            "  GRU_512\n",
            "  Dense_512\n",
            "  LogSoftmax\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH874SLvphVJ"
      },
      "source": [
        "### Training\n",
        "batch_size = 32\n",
        "max_length = 64"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grJmyUzgqBFb",
        "outputId": "205900af-fda9-4ec9-bb5b-0ad3c4ce7534"
      },
      "source": [
        "def n_used_lines(lines, max_length):\n",
        "    '''\n",
        "    Args: \n",
        "    lines: all lines of text an array of lines\n",
        "    max_length - max_length of a line in order to be considered an int\n",
        "    Return:\n",
        "    n_lines -number of efective examples\n",
        "    '''\n",
        "\n",
        "    n_lines = 0\n",
        "    for l in lines:\n",
        "        if len(l) <= max_length:\n",
        "            n_lines += 1\n",
        "    return n_lines\n",
        "\n",
        "num_used_lines = n_used_lines(lines, 64)\n",
        "print('Number of used lines from the dataset:', num_used_lines)\n",
        "print('Batch size (a power of 2):', int(batch_size))\n",
        "steps_per_epoch = int(num_used_lines/batch_size)\n",
        "print('Number of steps to cover one epoch:', steps_per_epoch)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of used lines from the dataset: 6029\n",
            "Batch size (a power of 2): 32\n",
            "Number of steps to cover one epoch: 188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZavKHUd8qU15"
      },
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "def train_model(model, data_generator, vocab_dict,batch_size=32, max_length=64, lines=lines, eval_lines=eval_lines, n_steps=1, output_dir='model/'): \n",
        "    \"\"\"Function that trains the model\n",
        "\n",
        "    Args:\n",
        "        model (trax.layers.combinators.Serial): GRU model.\n",
        "        data_generator (function): Data generator function.\n",
        "        batch_size (int, optional): Number of lines per batch. Defaults to 32.\n",
        "        max_length (int, optional): Maximum length allowed for a line to be processed. Defaults to 64.\n",
        "        lines (list, optional): List of lines to use for training. Defaults to lines.\n",
        "        eval_lines (list, optional): List of lines to use for evaluation. Defaults to eval_lines.\n",
        "        n_steps (int, optional): Number of steps to train. Defaults to 1.\n",
        "        output_dir (str, optional): Relative path of directory to save model. Defaults to \"model/\".\n",
        "\n",
        "    Returns:\n",
        "        trax.supervised.training.Loop: Training loop for the model.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    bare_train_generator =  data_generator(batch_size=batch_size, max_length=max_length, data_lines=lines,vocab_dict=vocab_dict)\n",
        "    infinite_train_generator = itertools.cycle(bare_train_generator)\n",
        "    \n",
        "    bare_eval_generator = data_generator(batch_size=batch_size, max_length=max_length, data_lines=eval_lines,vocab_dict=vocab_dict)\n",
        "    infinite_eval_generator = itertools.cycle(bare_eval_generator)\n",
        "   \n",
        "    train_task = training.TrainTask(\n",
        "        labeled_data=infinite_train_generator, # Use infinite train data generator\n",
        "        loss_layer=tl.CrossEntropyLoss(),   # Don't forget to instantiate this object\n",
        "        optimizer=trax.optimizers.Adam(learning_rate=0.0005),     # Don't forget to add the learning rate parameter\n",
        "        n_steps_per_checkpoint=50\n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "        labeled_data=infinite_eval_generator,    # Use infinite eval data generator\n",
        "        metrics=[tl.CrossEntropyLoss(), tl.Accuracy()], # Don't forget to instantiate these objects\n",
        "        n_eval_batches=3      # For better evaluation accuracy in reasonable time\n",
        "    )\n",
        "    \n",
        "    training_loop = training.Loop(model,\n",
        "                                  train_task,\n",
        "                                  eval_tasks=eval_task,\n",
        "                                  output_dir=output_dir)\n",
        "\n",
        "    training_loop.run(n_steps=n_steps)  ##each step equal to a 1 batch\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # We return this because it contains a handle to the model, which has the weights etc.\n",
        "    return training_loop"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZBZytgFqwLp"
      },
      "source": [
        "#help(trax.supervised.TrainTask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8kNkA-7raDY"
      },
      "source": [
        "#help(trax.supervised.training.Loop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "j-ut3XRMsnHZ",
        "outputId": "38cc4f6a-daca-4018-b3fb-b50a1749b79d"
      },
      "source": [
        "epoch=50\n",
        "training_loop = train_model(GRULM(), data_generator,Vocab,n_steps=steps_per_epoch*epoch)\n",
        "#training_loop = train_model(GRULM(), data_generator,Vocab,n_steps=steps_per_epoch*epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:374: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:387: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step   5650: Ran 50 train steps in 101.10 secs\n",
            "Step   5650: train CrossEntropyLoss |  1.08835423\n",
            "Step   5650: eval  CrossEntropyLoss |  2.04271452\n",
            "Step   5650: eval          Accuracy |  0.46328283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-f3ff1bebcf36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRULM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-d4bbabfbbde6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, data_generator, vocab_dict, batch_size, max_length, lines, eval_lines, n_steps, output_dir)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                   output_dir=output_dir)\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtraining_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m##each step equal to a 1 batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_steps)\u001b[0m\n\u001b[1;32m    433\u001b[0m           \u001b[0mloss_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_changed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# optimizer_metrics and loss are replicated on self.n_devices, a few\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36m_run_one_step\u001b[0;34m(self, task_index, task_changed)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     (loss, stats) = trainer.one_step(\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     )\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/trax/optimizers/trainer.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, batch, rng, step, learning_rate)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m# NOTE: stats is a replicated dictionary of key to jnp arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     (new_weights, new_slots), new_state, stats = self._accelerated_update_fn(\n\u001b[0;32m--> 148\u001b[0;31m         (weights, self._slots), step, self._opt_params, batch, state, rng)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvlog_is_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vim62L0YpC5"
      },
      "source": [
        "def test_model(preds, target):\n",
        "    \"\"\"Function to test the model.\n",
        "\n",
        "    Args:\n",
        "        preds (jax.interpreters.xla.DeviceArray): Predictions of a list of batches of tensors corresponding to lines of text.\n",
        "        target (jax.interpreters.xla.DeviceArray): Actual list of batches of tensors corresponding to lines of text.\n",
        "\n",
        "    Returns:\n",
        "        float: log_perplexity of the model.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    total_log_ppx = np.sum(preds *tl.one_hot(target,n_categories=preds.shape[-1]), axis= -1) # HINT: tl.one_hot() should replace one of the Nones\n",
        "\n",
        "    non_pad = 1.0 - np.equal(target, 0)          # You should check if the target equals 0\n",
        "    ppx = total_log_ppx * non_pad                             # Get rid of the padding\n",
        "\n",
        "    log_ppx = np.sum(ppx) / np.sum(non_pad)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return -log_ppx"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgriHFjJYzM4",
        "outputId": "a68a0224-ff55-41d9-fc08-36aa0e7e178b"
      },
      "source": [
        "model = GRULM()\n",
        "model.init_from_file('model/model.pkl.gz')\n",
        "batch = next(data_generator(batch_size, max_length, lines, Vocab,shuffle=False))\n",
        "print(batch[0].shape)\n",
        "preds = model(batch[0])\n",
        "log_ppx = test_model(preds, batch[1])\n",
        "print('The log perplexity and perplexity of your model are respectively', log_ppx, np.exp(log_ppx))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 64)\n",
            "The log perplexity and perplexity of your model are respectively 1.0888716 2.9709198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qEjdiENdDRp",
        "outputId": "ab5b229f-f288-449e-86f7-429ce15f7801"
      },
      "source": [
        "inv_Vocab = {v: k for k, v in Vocab.items()}\n",
        "inv_Vocab"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '',\n",
              " 1: '__EOS__',\n",
              " 2: '__UNK__',\n",
              " 3: 'ا',\n",
              " 4: 'ل',\n",
              " 5: ' ',\n",
              " 6: 'ي',\n",
              " 7: 'ه',\n",
              " 8: 'س',\n",
              " 9: 'ق',\n",
              " 10: 'ی',\n",
              " 11: 'د',\n",
              " 12: 'ر',\n",
              " 13: 'ک',\n",
              " 14: 'و',\n",
              " 15: 'ن',\n",
              " 16: 'م',\n",
              " 17: 'ز',\n",
              " 18: 'ج',\n",
              " 19: 'چ',\n",
              " 20: 'ع',\n",
              " 21: 'ش',\n",
              " 22: 'ب',\n",
              " 23: 'گ',\n",
              " 24: 'ت',\n",
              " 25: 'پ',\n",
              " 26: 'غ',\n",
              " 27: 'خ',\n",
              " 28: 'آ',\n",
              " 29: 'ص',\n",
              " 30: 'ح',\n",
              " 31: 'ف',\n",
              " 32: 'ظ',\n",
              " 33: 'ط',\n",
              " 34: 'ث',\n",
              " 35: 'ض',\n",
              " 36: 'ذ',\n",
              " 37: 'ژ',\n",
              " 38: 'Y'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfXWsWO8bp-S",
        "outputId": "d5f55c9b-2aa9-41dd-e911-adb36f476952"
      },
      "source": [
        "def gumbel_sample(log_probs, temperature=1.0):\n",
        "    \"\"\"Gumbel sampling from a categorical distribution.\"\"\"\n",
        "    u = numpy.random.uniform(low=1e-6, high=1.0 - 1e-6, size=log_probs.shape)\n",
        "    g = -np.log(-np.log(u))\n",
        "    return np.argmax(log_probs + g * temperature, axis=-1)\n",
        "\n",
        "def predict(num_chars, prefix):\n",
        "    inp = [ord(c) for c in prefix]\n",
        "    result = [c for c in prefix]\n",
        "    max_len = len(prefix) + num_chars\n",
        "    for _ in range(num_chars):\n",
        "        cur_inp = np.array(inp + [0] * (max_len - len(inp)))\n",
        "        outp = model(cur_inp[None, :])  # Add batch dim.\n",
        "        next_char = gumbel_sample(outp[0, len(inp)])\n",
        "        inp += [int(next_char)]\n",
        "       \n",
        "        if inp[-1] == 1:\n",
        "            break  # EOS\n",
        "        result.append(inv_Vocab[int(next_char)])\n",
        "    \n",
        "    return \"\".join(result)\n",
        "\n",
        "print(predict(64, \"\"))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "دوش بخت هر کم برنه بدنامی کرده شنيد\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aib8xUJNdR5D",
        "outputId": "158d0653-2095-43d9-fdae-45b924cc36bf"
      },
      "source": [
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ز گفت بخت جوی کلک عشقياض بلاکر\n",
            "خم ابروی تو تعويی فرخ پگياريست\n",
            "من گفتا بگذشتم ای مفلس گفريبد کی شاه\n",
            "گوش از ما مست تو مهر عنان بپوش\n",
            "حافظ به رقيب و شربلبی و عطر گذار\n",
            "هيچ الست شيخ شد و آب رويم\n",
            "تر مبروی در فضلی هر چه ز گست بنشان هوا\n",
            "نالحم علل آفريا مده و يار دگر\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv1_Xp2VeANA",
        "outputId": "a59c3938-5d69-4a16-aef2-4137efccc4be"
      },
      "source": [
        "#Poet samples:\n",
        "\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))\n",
        "print(predict(48, \"\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "شب جگر دهد در شمش حافظ ای صبح\n",
            "زقد عشق تو هيچ رو نه خال تو بست\n",
            "که درداغ علم و افغان را چه شود جان\n",
            "در هصطشتان خرقه حافظا نهره بار\n",
            "از زمانش دهان عمل بفرما که منعمان\n",
            "شکفته ما گذری هيتی غير منمی\n",
            "بس شکرتو روی فرخ پی فرخنده پياله بود\n",
            "هر بخت عدد که در خانگيست در فرزهان\n",
            "درکش اندر سر فرخ پی خات و هيچ را\n",
            "بلال خدا که پرتوان شمع دل است\n",
            "گفت خاتی به راه طريقت گذر نماند\n",
            "به فقل رای جين کرم بی فری داور کنم\n",
            "و از می خور و خون دلم راه در مذهب آباد\n",
            "در کمر خانقاه و حريفان دهان\n",
            "فراغت آن آن را از بيا و بهر خدا بکن\n",
            "حافظ مريد فشان خود است حالش\n",
            "گر خاک بر سر خود خون که تهباری کند\n",
            "جم خون و تدبير نثارم و به انداز افتض\n",
            "رضش عشق که گفت بسی تو با خاک بجاست\n",
            "که طاله قصد جمال داود و نياز\n",
            "ز رنج عالم تيز عنبرقف اليفان\n",
            "زبان ز شربلب چه جان طلغمت همه حافظ\n",
            "واعظ ما چو لبلای از دست ما فرعنگيست\n",
            "که آنپرسم ژهايت از سر بر نداده يار\n",
            "چو حال دجر تو را چه گوش خور بهشت\n",
            "شرم بده عشق کرشمه چين به سر آرد\n",
            "غرض ابروی دل که در آن گرفت چو مکن\n",
            "کجا بيمويت عشقبازان را چه سلطل\n",
            "گريه چه خون دل چهره حورت رخ خوبی\n",
            "لنگی دريبا به گيسوی حرام افتاد\n",
            "چو هفتاد باد آن حيرهان فزن چشم هدست\n",
            "تا ز طوبی که شد مفروش آمد\n",
            "نهادم درگشتند و دربان خرابات\n",
            "جاودان که در اين منزل جانان راز کند\n",
            "از رنگ خونم آورد فال روح يار آگو\n",
            "جمال زر نهان از آن خواهد شد\n",
            "حافظ طمع ببر و دوش در پاک آوار\n",
            "تو را در معامله چو لطف است و نازک نيست\n",
            "رسد لقيف که رسم فراغق بلوف\n",
            "که به خاک خواب خطا گم رساز کند\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0PwxKH85Ixh",
        "outputId": "4c8c5d22-7069-4708-a514-37fbd8e656f9"
      },
      "source": [
        "## More samples\n",
        "\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "علاج بيلوده مژده اما دل درخرفت\n",
            "کت خود که پرفشان چو چراغ ديده شکايان\n",
            "هر چند بر صنگ و ز شمشير شد عجب خواند\n",
            "ترک و حيل دريبا به سر نماز من است\n",
            "يا رب اين تقايی در آن نرآيد کاين شهاب\n",
            "گر باد آمده چاک خواب نخواهد لافی\n",
            "با حافظ و از غم مسغول در خم چوگان\n",
            "آن گه پيام تا خصم بی چنان حافظ\n",
            "تا سر گوش به جبرنه از آن که در طلب گير\n",
            "يا رند نقش عشقی خدای روزن دريغ\n",
            "چو نگرد علم شادی شود عزيز است\n",
            "خيز تا از چو نی حور باده به عياری\n",
            "غلام دهارت کرم بج عالق است مناب\n",
            "بنجه حافظ از دل ميخانه پای فان\n",
            "جمال اعتماد و شفا بخوان است ولی\n",
            "بوی شرف دلا محتسب شهر حور و حرمان است\n",
            "بی لاله ميروخ تو بدرده بر خضک\n",
            "بر عزم تو خود دادی که صبا بر باری داند\n",
            "بی طلبت يار من آرش که چابدان هر دم\n",
            "سود و دانم که به دست نشنادم\n",
            "همچو گل گفته و بلکن مرامت رسيد\n",
            "از بخت من او خندان به خروشد نگارا\n",
            "آن کسان که من جز فرمانده عشق\n",
            "غلام دم کز وصل تو تدبير کماند\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrWy7n3S6oOh",
        "outputId": "32e2909d-47d9-43c7-8532-bff1b5b5d2f4"
      },
      "source": [
        "\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "فلک خاطر مجموع هوساز و نداد\n",
            "که من از پرتشمه نفس رفتنج ابرو\n",
            "آه صافيت شعر دانست پرويی چون ای دل کشيد\n",
            "منت هر آن يک جهان نقاب و رندی نيست\n",
            "ما که صوفی ز مدحت انجم يار شما\n",
            "فراغت مداون که مبادا خلوتی حافظ\n",
            "پس اگر به صيادت گفتم که سفله گفت\n",
            "به پياله صيام که کند قامتی دار\n",
            "چون من سايه آب و رحمت نبود غماز\n",
            "وگر تربلی گفتنم همناز من و تو باد\n",
            "حباب و کرم سوی فرخ پی کف ساقی گيرنم\n",
            "به قدت رکن مانکبش او به جان خواند\n",
            "از رخ زرق به خون آشفته شود\n",
            "حقوق صحبت گوهی که از ما بگويمت\n",
            "ز افتاک هر ديده حافظ خور نماندست\n",
            "در سينه جام جهان افتاد بلند\n",
            "جهان نشود روانی به تماشا بچنان افتادست\n",
            "عهدثه شيرينان و حريف نباشد\n",
            "در اين خيالت ای ساقی و ابروی ما چند\n",
            "بت سر عهد ملک دی و سحر گذران\n",
            "ديوان و نزدين شاه عشقباجان را\n",
            "بزم در آخر به بام رها ببرد و کنوم\n",
            "جای ديوانه ياد قدم و من زمانی چو شمع\n",
            "گفت آن کش نيست زمانی دولت بنده مقصر تو\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYu1Mffh-Yd7",
        "outputId": "0d264d43-54a1-4b4f-8c41-5c7cf75d5122"
      },
      "source": [
        "\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))\n",
        "print(predict(64, \"\"))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "گر نرسد ز مصلحت نيخت که ما را خواهد\n",
            "بر اين پرده نگه دار زدم ديده شاد\n",
            "لنگر شيرين و بيماری هجر تو زد از نفس\n",
            "رحم اگر چه و سوخته دل راه و نگار\n",
            "اين چه سفله که رخصی و روی می خورده باد\n",
            "صبر خويش بر زلف سوختگان بازآيد\n",
            "فدای که آرت از اعغر تو همان مشنيست\n",
            "تا جان کی به باد غم از شما داد و برآر\n",
            "همچو ار بدمندم صرف ببر کز نماند\n",
            "به خنده گفتم بی چو طلعت خويشم\n",
            "ماهرزانی همنشين دارم ز من باشد\n",
            "که باد آن کس که هزارش مرحال افتاد\n",
            "سمن سبک و دختر دار کمن شويم\n",
            "هر آن کس که می خور شدی به من بزد ولی\n",
            "بشنو که خواب خوش ديدار شمابخش\n",
            "فغان که روز که باده پرستان همه فال\n",
            "خواهی از آشنا منور از سر نمازی\n",
            "حافظ ببر و وفا نيست جای حافظ\n",
            "برکليد لعت تو تنگ در چين زمانی\n",
            "مژده در غزل خرابات است مجلق کرد\n",
            "عشقبازان را خلافيت شاهانه زد و سول\n",
            "که داخت برخيز کرد و تمکان بازرسان\n",
            "که در پای خم ابروا ياد شاه\n",
            "که آخر به يک ديده حافظ عزيز امل\n",
            "هر دست به دستم نديدم رسيد امان\n",
            "گر طريق عشف فتضه از فلاصل دوران غير\n",
            "خوشدلی ای نصيب تو در هزاران رواست\n",
            "با يار مفلس شراب آلوده\n",
            "وين بشنويد رندان پاکداريم\n",
            "جلوه و خرد وصل کنم به باده دهد\n",
            "بحر ميان خسروان ما را بخورد نفسی\n",
            "اندر اين سيک گريه نشين شاه شود\n",
            "چو صبرم آن سرو ليلی گنف زبان غريب\n",
            "خرام و خورشيد انسان خوانديمگاران سنگ است\n",
            "نه من به حق قند و شينه صوفی زهی آورد\n",
            "طرت و چون به خرافشان خوش امان\n",
            "چو سنگ خلوتيان قدح باده و صفا مخت\n",
            "دردی نکرد که با دم غم تو داد ز من\n",
            "در پای عنم گيت از دولت همان بين\n",
            "گر مجلس شاه ببينش جام نيست که نيست\n",
            "جهان گويد که غم دوشم در مژها کنی دارد\n",
            "کردم گفتم که به جای خويش نگاه\n",
            "ز بدنامی چه سالک داران خورشيد آشنا\n",
            "وان پاک دير راه به مدر ما شکند زبان شوريد\n",
            "عيبم و آتش که دل و نقش ازل برقجازم\n",
            "فرصت تا همه موی صنوبر دولت دارد\n",
            "غلام نرگس نتوان بده سر در صحبت گير\n",
            "که دلديم در صدر نگار بيما را\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}